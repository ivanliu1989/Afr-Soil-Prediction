install.packages(c("aplpack", "caTools", "coin", "corrgram", "DBI", "devtools", "e1071", "flexmix", "forecast", "formatR", "fpc", "geosphere", "GGally", "gplots", "gsubfn", "HH", "Hmisc", "htmltools", "httr", "jsonlite", "labeling", "Lahman", "maps", "markdown", "MASS", "mclust", "mime", "NLP", "party", "pcaPP", "proxy", "rattle", "Rcmdr", "RcppArmadillo", "rgl", "rmarkdown", "sandwich", "swirl", "testthat", "UsingR", "xlsxjars", "xtable"))
setwd("C:\\Users\\Ivan.Liuyanfeng\\Desktop\\Data_Mining_Work_Space\\Afr-Soil-Prediction")
library(e1071)
train <- read.csv("Data/training.csv",header=TRUE,stringsAsFactors=FALSE)
test <- read.csv("Data/sorted_test.csv",header=TRUE,stringsAsFactors=FALSE)
submission <- test[,1]
submission
labels <- train[,c("Ca","P","pH","SOC","Sand")]
labels
train <- train[,c(2:2655,2671:3579)]
test <- test[,c(2:2655,2671:3579)]
ncol(labels)
svms <- lapply(1:ncol(labels),
function(i)
{
svm(train,labels[,i],cost=10000,scale=FALSE)
})
svms
predictions <- sapply(svms,predict,newdata=test)
colnames(predictions) <- c("Ca","P","pH","SOC","Sand")
submission <- cbind(PIDN=submission,predictions)
write.csv(submission,"r_first_try.csv",row.names=FALSE,quote=FALSE)
library(e1071); library(caret)
index <- createDataPartition(y = train, p=0.8, list=F)
dim(train)
str(train)
index <- createDataPartition(y = train$Ca, p=0.8, list=F)
setwd("C:\\Users\\Ivan.Liuyanfeng\\Desktop\\Data_Mining_Work_Space\\Afr-Soil-Prediction")
library(e1071); library(caret)
train <- read.csv("Data/training.csv",header=TRUE,stringsAsFactors=FALSE)
test <- read.csv("Data/sorted_test.csv",header=TRUE,stringsAsFactors=FALSE)
submission <- test[,1]
labels <- train[,c("Ca","P","pH","SOC","Sand")]
index <- createDataPartition(y = train$Ca, p=0.8, list=F)
table(index)
index
train_train <- train[index,]
train_test <- train[-index,]
train <- train[,c(2:2655,2671:3579)]
test <- test[,c(2:2655,2671:3579)]
train_train <- train[index,]
train_test <- train[-index,]
svms <- lapply(1:ncol(labels),
function(i)
{
svm(train_train,labels[,i],cost=10000,scale=FALSE)
})
labels_train <- labels[index,]
labels_test <- labels[-index,]
svms <- lapply(1:ncol(labels_train),
function(i)
{
svm(train_train,labels[,i],cost=10000,scale=FALSE)
})
svms <- lapply(1:ncol(labels_train),
function(i)
{
svm(train_train,labels_train[,i],cost=10000,scale=FALSE)
})
labels_train[1]
svms[1]
pred_Ca <- predict(svms[1], train_train)
confusionMatrix(pred_Ca, labels_train[1])
pred_Ca
confusionMatrix(pred_Ca, as.vector(labels_train[1]))
confusionMatrix(pred_Ca, as.list(labels_train[1]))
labels_train[1]
pred_Ca
confusionMatrix(pred_Ca[[1]], labels_train[1])
pred_Ca[[1]]
labels_train[1]
labels_train$Ca
confusionMatrix(pred_Ca[[1]], labels_train$Ca)
)
confusionMatrix(as.vector(pred_Ca[[1]]), labels_train$Ca)
pred_Ca
pred_Ca
svms[1]
pred_Ca <- predict(svms[[1]], train_train)
confusionMatrix(as.vector(pred_Ca[[1]]), labels_train$Ca)
confusionMatrix(pred_Ca[1], labels_train$Ca)
pred_Ca[1]
confusionMatrix(pred_Ca, labels_train$Ca)
pred_Ca
labels_train$Ca
str(pred_Ca)
class(pred_Ca)
class(labels_train$Ca)
str(labels_train$Ca)
str(pred_Ca)
table(pred_Ca, labels_train$Ca)
pred_Ca
RSME(svms)
RMSE(svms)
RMSE(pred_Ca)
RMSE(svms[[1]])
?RMSE
RMSE(train_train)
postResample(pred_Ca, train_train)
pred_Ca
postResample(pred_Ca, train_train$Ca)
train_train$Ca
train_train
summary(svms)
summary(svms[1])
summary(svms[[1]])
RMSE(svms[[1]])
postResample(pred_Ca, labels$Ca)
train_train
labels$Ca
pred_Ca
as.vector(pred_Ca)
postResample(as.vector(pred_Ca), labels$Ca)
RMSE(as.vector(pred_Ca), labels$Ca)
R2(as.vector(pred_Ca), labels$Ca)
setwd('H:\\Machine Learning\\Afr-Soil-Prediction')
require(caret);
train <- read.csv("data/training.csv",header=TRUE,stringsAsFactors=FALSE)
test <- read.csv("data/sorted_test.csv",header=TRUE,stringsAsFactors=FALSE)
labels <- train[,c("Ca","P","pH","SOC","Sand")] # y
depth <- train$Depth # Depth-train
depth[which(depth=='Topsoil')] <- 1;
depth[which(depth=='Subsoil')] <- 0
depth_test <- test$Depth # Depth-test
depth_test[which(depth_test=='Topsoil')] <- 1;
depth_test[which(depth_test=='Subsoil')] <- 0
ID_test <- test[,1] # test-ID
ID_train <- train[,1] # train-ID
#### Exclude CO2 and ID
rm_index <- c(1, 2656:2670, 3595:3600)
rm_index2 <- c(1, 2656:2670, 3595)
train <- train[,-rm_index]
test <- test[,-rm_index2]
dim(test);dim(train);identical(names(train), names(test))
total_data <- rbind(train,test); dim(total_data)
set.seed(888)
### combine datasets
train_Ca <- cbind(Ca=labels$Ca, train, Depth=depth)
train_P <- cbind(Ca=labels$P, train, Depth=depth)
train_pH <- cbind(Ca=labels$pH, train, Depth=depth)
train_SOC <- cbind(Ca=labels$SOC, train, Depth=depth)
train_Sand <- cbind(Ca=labels$Sand, train, Depth=depth)
test <- cbind(PIDN=ID_test, test, Depth=depth_test)
dim(train_Ca);dim(train_SOC);dim(test);
save(train_Ca, train_P, train_SOC, train_Sand, train_pH, test,
file="data/datasets_all_01Oct2014.RData")
require(caret); require(hydroGOF) #rmse
install.packages("hydroGOF")
rm(list=ls())
setwd('H:\\Machine Learning\\Afr-Soil-Prediction')
require(caret); require(hydroGOF) #rmse
load('data/datasets_all_01Oct2014.RData')
dim(test);dim(train_Ca);dim(train_P);
dim(train_SOC);dim(train_Sand);dim(train_pH)
ID <- as.data.frame(test[,1])
names(ID)<-'PIDN'
index_P <- createDataPartition(train_P$P, p=0.75, list = F)
train_P_1 <- train_P[index_P,]
train_P_2 <- train_P[-index_P,]
index_P <- createDataPartition(train_P$P, p=0.75, list = F)
head(train_P)
head(train_P$p)
head(train_P$P)
rm(list=ls())
gc()
setwd('H:\\Machine Learning\\Afr-Soil-Prediction')
require(caret);
train <- read.csv("data/training.csv",header=TRUE,stringsAsFactors=FALSE)
test <- read.csv("data/sorted_test.csv",header=TRUE,stringsAsFactors=FALSE)
labels <- train[,c("Ca","P","pH","SOC","Sand")] # y
depth <- train$Depth # Depth-train
depth[which(depth=='Topsoil')] <- 1;
depth[which(depth=='Subsoil')] <- 0
depth_test <- test$Depth # Depth-test
depth_test[which(depth_test=='Topsoil')] <- 1;
depth_test[which(depth_test=='Subsoil')] <- 0
ID_test <- test[,1] # test-ID
ID_train <- train[,1] # train-ID
rm_index <- c(1, 2656:2670, 3595:3600)
rm_index2 <- c(1, 2656:2670, 3595)
names(train)
rm_index <- c(1, 2656:2670, 3595:3600)
rm_index2 <- c(1, 2656:2670, 3595)
train <- train[,-rm_index]
test <- test[,-rm_index2]
dim(test);dim(train);identical(names(train), names(test))
total_data <- rbind(train,test); dim(total_data)
set.seed(888)
train_Ca <- cbind(Ca=labels$Ca, train, Depth=depth)
train_P <- cbind(P=labels$P, train, Depth=depth)
train_pH <- cbind(pH=labels$pH, train, Depth=depth)
train_SOC <- cbind(SOC=labels$SOC, train, Depth=depth)
train_Sand <- cbind(Sand=labels$Sand, train, Depth=depth)
test <- cbind(PIDN=ID_test, test, Depth=depth_test)
dim(train_Ca);dim(train_SOC);dim(test);
### Write database ###
save(train_Ca, train_P, train_SOC, train_Sand, train_pH, test,
file="data/datasets_all_01Oct2014.RData")
rm(list=ls())
load('data/datasets_all_01Oct2014.RData')
dim(test);dim(train_Ca);dim(train_P);
dim(train_SOC);dim(train_Sand);dim(train_pH)
ID <- as.data.frame(test[,1])
names(ID)<-'PIDN'
index_P <- createDataPartition(train_P$P, p=0.75, list = F)
train_P_1 <- train_P[index_P,]
train_P_2 <- train_P[-index_P,]
set.seed(888)
fitControl <- trainControl(method="adaptive_cv",number=10,
repeats=5, summaryFunction = defaultSummary,
returnResamp = "all",
adaptive=list(min=10,alpha=.05,
method='BT',complete=T))
P <- rep(mean(train_P_1$P), n=length(test_P_1$P))
P <- rep(mean(train_P_1$P), n=length(train_P_2$P))
rmse(P, train_P_2$P)
P
P <- rep(mean(train_P_1$P), length(train_P_2$P))
P
rmse(P, train_P_2$P)
P <- rep(median(train_P_1$P), length(train_P_2$P))
rmse(P, train_P_2$P)
median(train_P_1$P)
length(train_P_2$P)
P <- rep(mean(train_P_1$P), length(train_P_2$P))
rmse(P, train_P_2$P)
fit_P_ridge <- train(P~., data=train_P_1,
method='ridge',
trControl = fitControl,
preProc = c('center','scale'),
tuneLength=10,
# tuneGrid = Grid,
verbose=T,
metric='RMSE')
